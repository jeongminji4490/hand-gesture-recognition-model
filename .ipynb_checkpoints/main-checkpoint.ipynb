{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1589a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing \n",
    "# 주석 추가\n",
    "falseSet_dir = '0/' \n",
    "trueSet_dir = '1/' \n",
    "fdataset_path = '' \n",
    "tdataset_path = ''\n",
    "\n",
    "if not os.path.exists(falseSet_dir):\n",
    "    os.makedirs(falseSet_dir) \n",
    "if not os.path.exists(trueSet_dir):\n",
    "    os.makedirs(trueSet_dir)\n",
    "    \n",
    "fdataset_list = os.listdir(fdataset_path)\n",
    "tdataset_list = os.listdir(tdataset_path)\n",
    "\n",
    "# 살색 범위\n",
    "lower = np.array([0, 48, 80], dtype = \"uint8\")\n",
    "upper = np.array([20, 255, 255], dtype = \"uint8\")\n",
    "\n",
    "# false dataset\n",
    "i = 0\n",
    "for file in fdataset_list:\n",
    "    src = cv2.imread(fdataset_path + file)\n",
    "    src2 = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "    mask_src = cv2.inRange(src2, lower, upper) #살색 부분 이진화\n",
    "    f_numpy = np.array(mask_src, 'uint8')\n",
    "    f_numpy = f_numpy/255.0\n",
    "    resize_f = cv2.resize(f_numpy, dsize=(28, 28), interpolation=cv2.INTER_AREA) # 이미지 리사이징\n",
    "    cv2.imwrite(os.path.join(falseSet_dir, '0_hand_' + str(i) + '.jpg'), resize_f)\n",
    "    i += 1\n",
    "\n",
    "# true dataset\n",
    "i = 0\n",
    "for file in tdataset_list:\n",
    "    src = cv2.imread(tdataset_path + file)\n",
    "    src2 = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "    mask_src = cv2.inRange(src2, lower, upper)\n",
    "    f_numpy = np.array(mask_src, 'uint8')\n",
    "    f_numpy = f_numpy/255.0\n",
    "    resize_f = cv2.resize(f_numpy, dsize=(28, 28), interpolation=cv2.INTER_AREA) \n",
    "    cv2.imwrite(os.path.join(trueSet_dir, '1_hand_' + str(i) + '.jpg'), resize_f)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b01bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "X = []\n",
    "Y = []\n",
    "categories = [\"0\", \"1\"] # 0 -> false, 1 -> true\n",
    "num_classes = len(categories) \n",
    "dataset_dir = ''\n",
    "for idx, categorie in enumerate(categories):\n",
    "    label = [0 for i in range(num_classes)]\n",
    "    label[idx] = 1\n",
    "    image_dir = dataset_dir + categorie + '/'\n",
    "    \n",
    "    for top, dir, f in os.walk(image_dir):\n",
    "        for filename in f:\n",
    "            img = Image.open(image_dir + filename)\n",
    "            img_numpy = np.array(img, 'uint8')\n",
    "            X.append(img_numpy)\n",
    "            Y.append(label)   \n",
    "            \n",
    "x = np.array(X) \n",
    "y = np.array(Y) \n",
    "\n",
    "# 트레이닝 데이터와 테스트 데이터로 분할\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y)\n",
    "xy = (x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to fit model input size\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5adecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "MODEL_DIR = 'model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "    \n",
    "modelpath = 'model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath = modelpath,\n",
    "                              monitor = 'val_loss',\n",
    "                              verbose = 1,\n",
    "                              save_best_only = True)\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss',\n",
    "                                       patience = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280e8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the model\n",
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test),\n",
    "                   epochs = 30, batch_size = 200, verbose = 0,\n",
    "                   callbacks = [early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc27857",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n accuracy : %.4f\" % (model.evaluate(x_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a graph\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker = '.', c='red', label = 'Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker = '.', c='blue', label = 'Trainset_loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
